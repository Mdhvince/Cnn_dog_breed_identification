{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XVJGVmZITygK"
   },
   "source": [
    "### Train CNN : Dog breed classification in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 476,
     "status": "ok",
     "timestamp": 1544879104658,
     "user": {
      "displayName": "Medhy Vinceslas",
      "photoUrl": "https://lh3.googleusercontent.com/-07-r4C_-SIk/AAAAAAAAAAI/AAAAAAAAAOU/sq--4MVCSjY/s64/photo.jpg",
      "userId": "03914062336656666029"
     },
     "user_tz": -60
    },
    "id": "wEM0NjfRT3Ex",
    "outputId": "4cec0481-0579-4e86-c384-b567ae9e95eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1653,
     "status": "ok",
     "timestamp": 1544879109963,
     "user": {
      "displayName": "Medhy Vinceslas",
      "photoUrl": "https://lh3.googleusercontent.com/-07-r4C_-SIk/AAAAAAAAAAI/AAAAAAAAAOU/sq--4MVCSjY/s64/photo.jpg",
      "userId": "03914062336656666029"
     },
     "user_tz": -60
    },
    "id": "u7GpM16EUTku",
    "outputId": "e0bc255f-77bf-43b8-8336-9a8e51b8d0eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog.ipynb  dogs\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/drive/My Drive/Colab Notebooks/dog_classifier/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4605,
     "status": "ok",
     "timestamp": 1544879115300,
     "user": {
      "displayName": "Medhy Vinceslas",
      "photoUrl": "https://lh3.googleusercontent.com/-07-r4C_-SIk/AAAAAAAAAAI/AAAAAAAAAOU/sq--4MVCSjY/s64/photo.jpg",
      "userId": "03914062336656666029"
     },
     "user_tz": -60
    },
    "id": "q5k6QCRTVBZu",
    "outputId": "0f37ec16-8d4a-4400-f724-1e28346a8d91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Collecting pillow>=4.1.1 (from torchvision)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Installing collected packages: pillow\n",
      "  Found existing installation: Pillow 4.0.0\n",
      "    Uninstalling Pillow-4.0.0:\n",
      "      Successfully uninstalled Pillow-4.0.0\n",
      "Successfully installed pillow-5.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9258,
     "status": "ok",
     "timestamp": 1544879127098,
     "user": {
      "displayName": "Medhy Vinceslas",
      "photoUrl": "https://lh3.googleusercontent.com/-07-r4C_-SIk/AAAAAAAAAAI/AAAAAAAAAOU/sq--4MVCSjY/s64/photo.jpg",
      "userId": "03914062336656666029"
     },
     "user_tz": -60
    },
    "id": "LxvPyUFszk7-",
    "outputId": "faf4c2ba-c1cb-465a-e1a9-fd30c5689e87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow==4.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
      "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: Pillow\n",
      "  Found existing installation: Pillow 5.3.0\n",
      "    Uninstalling Pillow-5.3.0:\n",
      "      Successfully uninstalled Pillow-5.3.0\n",
      "Successfully installed Pillow-4.0.0\n",
      "Collecting PIL\n",
      "\u001b[31m  Could not find a version that satisfies the requirement PIL (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for PIL\u001b[0m\n",
      "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
      "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.4)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.0.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.7)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n"
     ]
    }
   ],
   "source": [
    "# I need these line to run the cell after (stackoverflow)\n",
    "!pip install Pillow==4.0.0\n",
    "!pip install PIL\n",
    "!pip install image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pSR-SYjDTygL"
   },
   "source": [
    "##### Import the necessary module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2t6QI3BZTygN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1544879139215,
     "user": {
      "displayName": "Medhy Vinceslas",
      "photoUrl": "https://lh3.googleusercontent.com/-07-r4C_-SIk/AAAAAAAAAAI/AAAAAAAAAOU/sq--4MVCSjY/s64/photo.jpg",
      "userId": "03914062336656666029"
     },
     "user_tz": -60
    },
    "id": "_D8CyjIUTygP",
    "outputId": "8adf0154-8fc6-4615-f638-fe0c347a7ed1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classes: 120 - images: 20580'"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "train_dir = \"/content/drive/My Drive/Colab Notebooks/dog_classifier/dogs\"\n",
    "transform = transforms.Compose([\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.Resize(255), #square shape\n",
    "                                transforms.CenterCrop(224), #square from the center of the image\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                     [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "classes = train_data.classes\n",
    "f\"classes: {len(classes)} - images: {len(train_data)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ua6hQzAsTygf"
   },
   "source": [
    "#### Train and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAch0fpRTygk"
   },
   "outputs": [],
   "source": [
    "def train_valid_split(training_set, validation_size):\n",
    "    \"\"\" Function that split our dataset into train and validation\n",
    "        given in parameter the training set and the % of sample for validation\"\"\"\n",
    "    \n",
    "    # obtain training indices that will be used for validation\n",
    "    num_train = len(training_set)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(validation_size * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    \n",
    "    return train_sampler, valid_sampler\n",
    "\n",
    "# Call it\n",
    "valid_size = 0.3\n",
    "train_sampler, valid_sampler = train_valid_split(train_data, valid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vKP05EypTygn"
   },
   "source": [
    "#### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "stkn6G9dTygp"
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                           sampler=train_sampler)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                           sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pnAZtZJHTygr"
   },
   "source": [
    "#### visualize image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AW5R_XVWTygr"
   },
   "outputs": [],
   "source": [
    "def visualise_image_data(data_loader, nb_images_to_display, classes): \n",
    "    \n",
    "    # helper function to un-normalize and display an image\n",
    "    def imshow(img):\n",
    "        img = img / 2 + 0.5  # unnormalize\n",
    "        plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
    "\n",
    "    # obtain one batch of training images\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    # convert images to numpy for display\n",
    "    images = images.numpy()\n",
    "\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(25, 4))\n",
    "    # display 20 images\n",
    "    for idx in np.arange(nb_images_to_display):\n",
    "        ax = fig.add_subplot(2, nb_images_to_display/2, idx+1, xticks=[], yticks=[])\n",
    "        imshow(images[idx])\n",
    "        ax.set_title(classes[labels[idx]])\n",
    "        \n",
    "\n",
    "#visualise_image_data(train_loader, 20, train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1544879153628,
     "user": {
      "displayName": "Medhy Vinceslas",
      "photoUrl": "https://lh3.googleusercontent.com/-07-r4C_-SIk/AAAAAAAAAAI/AAAAAAAAAOU/sq--4MVCSjY/s64/photo.jpg",
      "userId": "03914062336656666029"
     },
     "user_tz": -60
    },
    "id": "A6pJQXaiTygu",
    "outputId": "2efb8b71-fe82-4d0e-da39-f773158b86a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available... Training on GPU\n"
     ]
    }
   ],
   "source": [
    "if not train_on_gpu:\n",
    "    print('CUDA not available... Training on CPU')\n",
    "else:\n",
    "    print('CUDA available... Training on GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3421,
     "status": "ok",
     "timestamp": 1544892748634,
     "user": {
      "displayName": "Medhy Vinceslas",
      "photoUrl": "https://lh3.googleusercontent.com/-07-r4C_-SIk/AAAAAAAAAAI/AAAAAAAAAOU/sq--4MVCSjY/s64/photo.jpg",
      "userId": "03914062336656666029"
     },
     "user_tz": -60
    },
    "id": "CHfpskouyCXm",
    "outputId": "18e201bb-93d7-4c27-c5a2-f3b59f9c03d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.torch/models/resnet18-5c106cde.pth\n",
      "100%|██████████| 46827520/46827520 [00:02<00:00, 19954757.82it/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UTTNHxRFyJ8T"
   },
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1544892982930,
     "user": {
      "displayName": "Medhy Vinceslas",
      "photoUrl": "https://lh3.googleusercontent.com/-07-r4C_-SIk/AAAAAAAAAAI/AAAAAAAAAOU/sq--4MVCSjY/s64/photo.jpg",
      "userId": "03914062336656666029"
     },
     "user_tz": -60
    },
    "id": "oEWSiT9RyWwb",
    "outputId": "fb73ec5d-85d2-47b7-fb4d-faed5fef386f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input features: 512\n",
      "output features: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"input features: {model.fc.in_features}\") \n",
    "print(f\"output features: {model.fc.out_features}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1544893067399,
     "user": {
      "displayName": "Medhy Vinceslas",
      "photoUrl": "https://lh3.googleusercontent.com/-07-r4C_-SIk/AAAAAAAAAAI/AAAAAAAAAOU/sq--4MVCSjY/s64/photo.jpg",
      "userId": "03914062336656666029"
     },
     "user_tz": -60
    },
    "id": "bbtz4BHYTyg2",
    "outputId": "c11af4c8-6623-4237-be2f-4e598974f463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input features: 512\n",
      "output features: 120\n"
     ]
    }
   ],
   "source": [
    "#model = models.vgg19(pretrained=True)\n",
    "#print(f\"input features: {model.classifier[6].in_features}\") \n",
    "#print(f\"output features: {model.classifier[6].out_features}\") \n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "n_inputs = model.fc.in_features\n",
    "\n",
    "# new layers automatically have requires_grad = True\n",
    "last_layer = nn.Linear(n_inputs, len(classes))\n",
    "model.fc = last_layer\n",
    "\n",
    "\n",
    "print(f\"input features: {model.fc.in_features}\") \n",
    "print(f\"output features: {model.fc.out_features}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 945,
     "status": "ok",
     "timestamp": 1544893145605,
     "user": {
      "displayName": "Medhy Vinceslas",
      "photoUrl": "https://lh3.googleusercontent.com/-07-r4C_-SIk/AAAAAAAAAAI/AAAAAAAAAOU/sq--4MVCSjY/s64/photo.jpg",
      "userId": "03914062336656666029"
     },
     "user_tz": -60
    },
    "id": "r06fY2W2TyhD",
    "outputId": "81b3aaeb-2874-472b-8e04-54a8e4cca0bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=120, bias=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum = 0.9)\n",
    "#optimizer = optim.Adam(model.classifier.parameters(), lr=0.01)\n",
    "\n",
    "model.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cku85-TwTyhK"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4370575,
     "status": "ok",
     "timestamp": 1544897533211,
     "user": {
      "displayName": "Medhy Vinceslas",
      "photoUrl": "https://lh3.googleusercontent.com/-07-r4C_-SIk/AAAAAAAAAAI/AAAAAAAAAOU/sq--4MVCSjY/s64/photo.jpg",
      "userId": "03914062336656666029"
     },
     "user_tz": -60
    },
    "id": "ApFAGDaFTyhL",
    "outputId": "c70b4270-595f-45c1-b23d-139cd26781db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 11.258298341133143 \tValidation Loss: 4.159369619553571\n",
      "Validation loss decreased (inf --> 4.159369619553571).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 3.238472611820744 \tValidation Loss: 3.363288915527917\n",
      "Validation loss decreased (4.159369619553571 --> 3.363288915527917).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 2.4786687095187756 \tValidation Loss: 3.027306191816231\n",
      "Validation loss decreased (3.363288915527917 --> 3.027306191816231).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 2.07024934853136 \tValidation Loss: 3.046810354439088\n",
      "Epoch: 5 \tTraining Loss: 1.7952386319538012 \tValidation Loss: 2.9217399788026364\n",
      "Validation loss decreased (3.027306191816231 --> 2.9217399788026364).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 1.6173912597854292 \tValidation Loss: 2.928578448573542\n",
      "Epoch: 7 \tTraining Loss: 1.454512832563232 \tValidation Loss: 2.9521544127884307\n",
      "Epoch: 8 \tTraining Loss: 1.3379905105365242 \tValidation Loss: 2.967417995855598\n",
      "Epoch: 9 \tTraining Loss: 1.2172965526845574 \tValidation Loss: 2.9913660494774734\n",
      "Epoch: 10 \tTraining Loss: 1.1482844661832319 \tValidation Loss: 2.960329479967374\n",
      "Epoch: 11 \tTraining Loss: 1.0549226120271529 \tValidation Loss: 2.9247692097653997\n",
      "Epoch: 12 \tTraining Loss: 0.987833109582417 \tValidation Loss: 3.0505804152377527\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 12\n",
    "\n",
    "# This is to make sure that the 1st loss is  lower than sth and\n",
    "# Save the model according to this comparison\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # Keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "  \n",
    "    # Pre-trained model by default is set to train\n",
    "    for data, target in train_loader:\n",
    "      \n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()                                                    # Clear the gradient because it is saved at each step\n",
    "        output = model(data)                                                     # Forward\n",
    "        loss = criterion(output, target)                                         # Compute the loss\n",
    "        loss.backward()                                                          # Compute the gradient\n",
    "        optimizer.step()                                                         # Perform updates using calculated gradients\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    valid_loss = valid_loss/len(valid_loader)\n",
    "\n",
    "    # print training/validation statistics \n",
    "    print(f\"Epoch: {epoch} \\tTraining Loss: {train_loss} \\tValidation Loss: {valid_loss}\")\n",
    "\n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print(f\"Validation loss decreased ({valid_loss_min} --> {valid_loss}).  Saving model ...\")\n",
    "        torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/dog_classifier/model.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1544897679425,
     "user": {
      "displayName": "Medhy Vinceslas",
      "photoUrl": "https://lh3.googleusercontent.com/-07-r4C_-SIk/AAAAAAAAAAI/AAAAAAAAAOU/sq--4MVCSjY/s64/photo.jpg",
      "userId": "03914062336656666029"
     },
     "user_tz": -60
    },
    "id": "GqbjXMmMTyhR",
    "outputId": "f6f4de63-f89a-45a6-a45c-b50bb1bd9f51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loading...\n",
      "Model succefully loaded !\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Loading...\")\n",
    "model.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/dog_classifier/model.pt'))\n",
    "print(\"Model succefully loaded !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCFuKCfiTyhV"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    img = Image.open(image)\n",
    "    \n",
    "    # Resize image\n",
    "    if img.size[0] > img.size[1]:\n",
    "        img.thumbnail((10000, 256))\n",
    "    else:\n",
    "        img.thumbnail((256, 10000))\n",
    "        \n",
    "    # Crop image\n",
    "    bottom_margin = (img.height-224)/2\n",
    "    top_margin = bottom_margin + 224\n",
    "    left_margin = (img.width-224)/2\n",
    "    right_margin = left_margin + 224\n",
    "    \n",
    "    img = img.crop((left_margin, bottom_margin, right_margin,   \n",
    "                      top_margin))\n",
    "    \n",
    "    # Normalize image\n",
    "    img = np.array(img)/255\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = (img - mean)/std\n",
    "    \n",
    "    # move to first dimension --> PyTorch\n",
    "    img = img.transpose((2, 0, 1))\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def imshow(image, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dog.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
